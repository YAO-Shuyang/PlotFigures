{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mylib.statistic_test import *\n",
    "\n",
    "code_id = '0346 - GLM for all sessions'\n",
    "loc = os.path.join(figpath, code_id)\n",
    "mkdir(loc)\n",
    "\n",
    "from mylib.model.glms import GLM as GenearlizedLinearModel\n",
    "from mylib.model import EqualRateDriftModel, TwoProbDriftModel\n",
    "from mylib.model import TwoProbabilityIndependentModel\n",
    "from mylib.model import JointProbabilityModel\n",
    "from mylib.model import HMM\n",
    "from mylib.model import ContinuousHiddenStateModel\n",
    "from mylib.model import ProbabilityRNN, IntegrativeRNN\n",
    "\n",
    "from mylib.field.tracker_v2 import Tracker2d\n",
    "\n",
    "def fit_models(field_reg, GLM: np.ndarray, qualified_idx: np.ndarray, file_name: str, is_gate: bool = True):\n",
    "\n",
    "    res = {\n",
    "        \"Step\": [],\n",
    "        \"Loss\": [],\n",
    "        \"Model Type\": []\n",
    "    }\n",
    "    \n",
    "    for j in range(GLM.shape[2]):\n",
    "        mean, std = np.nanmean(GLM[:, :, j]), np.nanstd(GLM[:, :, j])\n",
    "        GLM[:, :, j] = (GLM[:, :, j] - mean) / std\n",
    "\n",
    "    GLMC = cp.deepcopy(GLM)    \n",
    "    GLM = GLM[:, :, [0, 1, 2, 4, 5, 6, 7, 8, 9]]\n",
    "    print(f\"Orignial shape: {field_reg.shape}, qualified shape: {qualified_idx.shape[0]}\")\n",
    "    #field_reg = field_reg[:, qualified_idx]\n",
    "    tracker = Tracker2d(field_reg=field_reg)\n",
    "    sequences = tracker.convert_to_sequence(is_gate=is_gate)\n",
    "    lengths = np.array([len(seq) for seq in sequences])\n",
    "    \n",
    "    max_length = np.max(lengths)\n",
    "    if max_length > 10:\n",
    "        sequences, glm_params = tracker.convert_for_glm(field_reg, GLM, least_length=10, is_seq_format=True, is_gate=is_gate)\n",
    "    else:\n",
    "        sequences, glm_params = tracker.convert_for_glm(field_reg, GLM, least_length=5, is_seq_format=True, is_gate=is_gate)\n",
    "    \n",
    "    train_size = int(len(sequences) * 0.8)\n",
    "    train_indices = np.random.choice(len(sequences), train_size, replace=False)\n",
    "    test_indices = np.setdiff1d(np.arange(len(sequences)), train_indices)\n",
    "    res['train_indices'] = train_indices\n",
    "    res['train_size'] = 0.8\n",
    "    res['sequences'] = sequences\n",
    "\n",
    "    train_seq = [sequences[i] for i in train_indices]\n",
    "    test_seq = [sequences[i] for i in test_indices]\n",
    "\n",
    "    res['train_indices'] = train_indices\n",
    "    res['train_size'] = 0.8\n",
    "    res['sequences'] = sequences\n",
    "    \n",
    "    train_seq = [sequences[i] for i in train_indices]\n",
    "    test_seq = [sequences[i] for i in test_indices]\n",
    "    M1 = EqualRateDriftModel()\n",
    "    M1.fit(train_seq)\n",
    "    res['Loss'].append(M1.calc_loss_along_seq(test_seq))\n",
    "    res['Model Type'].append(np.repeat(\"Model I - 1\", max_length-1))\n",
    "    res['Step'].append(np.arange(1, max_length))\n",
    "    res['Step'].append(np.arange(1, max_length))\n",
    "    \n",
    "    M12 = TwoProbDriftModel()\n",
    "    M12.fit(train_seq)\n",
    "    res['Loss'].append(M12.calc_loss_along_seq(test_seq))\n",
    "    res['Model Type'].append(np.repeat(\"Model I - 2\", max_length-1))\n",
    "    res['Step'].append(np.arange(1, max_length))\n",
    "\n",
    "    M2 = TwoProbabilityIndependentModel()\n",
    "    M2.fit(train_seq)\n",
    "    res['Loss'].append(M2.calc_loss_along_seq(test_seq))\n",
    "    res['Model Type'].append(np.repeat(\"Model II\", max_length-1))\n",
    "    res['Step'].append(np.arange(1, max_length))\n",
    "\n",
    "    M3 = JointProbabilityModel()\n",
    "    M3.fit(train_seq)\n",
    "    res['Loss'].append(M3.calc_loss_along_seq(test_seq))\n",
    "    res['Model Type'].append(np.repeat(\"Model III\", max_length-1))\n",
    "    res['Step'].append(np.arange(1, max_length))\n",
    "\n",
    "    M41 = HMM.process_fit(N=5, sequences=train_seq, n_iterations=100)\n",
    "    res['Loss'].append(M41.calc_loss_along_seq(test_seq))\n",
    "    res['Model Type'].append(np.repeat(\"Model IV - 5\", max_length-1))\n",
    "    res['Step'].append(np.arange(1, max_length))\n",
    "    \n",
    "    M42 = HMM.process_fit(N=10, sequences=train_seq, n_iterations=100)\n",
    "    res['Loss'].append(M42.calc_loss_along_seq(test_seq))\n",
    "    res['Model Type'].append(np.repeat(\"Model IV - 10\", max_length-1))\n",
    "    res['Step'].append(np.arange(1, max_length))\n",
    "\n",
    "    M43 = HMM.process_fit(N=20, sequences=train_seq, n_iterations=100)\n",
    "    res['Loss'].append(M43.calc_loss_along_seq(test_seq))\n",
    "    res['Model Type'].append(np.repeat(\"Model IV - 20\", max_length-1))\n",
    "    res['Step'].append(np.arange(1, max_length))\n",
    "\n",
    "    M44 = HMM.process_fit(N=40, sequences=train_seq, n_iterations=100)\n",
    "    res['Loss'].append(M44.calc_loss_along_seq(test_seq))\n",
    "    res['Model Type'].append(np.repeat(\"Model IV - 40\", max_length-1))\n",
    "    res['Step'].append(np.arange(1, max_length))\n",
    "\n",
    "    M51 = ContinuousHiddenStateModel('reci')\n",
    "    M51.fit(train_seq)\n",
    "    res['Loss'].append(M51.calc_loss_along_seq(test_seq))\n",
    "    res['Model Type'].append(np.repeat(\"Model V - linear\", max_length-1))\n",
    "    res['Step'].append(np.arange(1, max_length))\n",
    "\n",
    "    M52 = ContinuousHiddenStateModel('logistic')\n",
    "    M52.fit(train_seq)\n",
    "    res['Loss'].append(M52.calc_loss_along_seq(test_seq))\n",
    "    res['Model Type'].append(np.repeat(\"Model V - logistic\", max_length-1))\n",
    "    res['Step'].append(np.arange(1, max_length))\n",
    "\n",
    "    M53 = ContinuousHiddenStateModel('poly2')\n",
    "    M53.fit(train_seq)\n",
    "    res['Loss'].append(M53.calc_loss_along_seq(test_seq))\n",
    "    res['Model Type'].append(np.repeat(\"Model V - poly2\", max_length-1))\n",
    "    res['Step'].append(np.arange(1, max_length))\n",
    "    \n",
    "    M54 = ContinuousHiddenStateModel('poly3')\n",
    "    M54.fit(train_seq)\n",
    "    res['Loss'].append(M54.calc_loss_along_seq(test_seq))\n",
    "    res['Model Type'].append(np.repeat(\"Model V - poly3\", max_length-1))\n",
    "    res['Step'].append(np.arange(1, max_length))\n",
    "\n",
    "    M61 = ProbabilityRNN.process_fit(\n",
    "        sequences,\n",
    "        train_index=train_indices,\n",
    "        hidden_size=8,\n",
    "        lr=0.001,\n",
    "        epochs=1000, \n",
    "        batch_size=2048\n",
    "    )\n",
    "    res['Loss'].append(M61.calc_loss_along_seq(test_seq))\n",
    "    res['Model Type'].append(np.repeat(\"Model VI - 8\", max_length-1)) \n",
    "    res['Step'].append(np.arange(1, max_length))\n",
    "\n",
    "    M62 = ProbabilityRNN.process_fit(\n",
    "        sequences,\n",
    "        train_index=train_indices,\n",
    "        hidden_size=16,\n",
    "        lr=0.001,\n",
    "        epochs=1000, \n",
    "        batch_size=2048\n",
    "    )\n",
    "    res['Loss'].append(M62.calc_loss_along_seq(test_seq))\n",
    "    res['Model Type'].append(np.repeat(\"Model VI - 16\", max_length-1)) \n",
    "    res['Step'].append(np.arange(1, max_length))\n",
    "\n",
    "    M63 = ProbabilityRNN.process_fit(\n",
    "        sequences,\n",
    "        train_index=train_indices,\n",
    "        hidden_size=32,\n",
    "        lr=0.001,\n",
    "        epochs=1000, \n",
    "        batch_size=2048\n",
    "    )\n",
    "    res['Loss'].append(M63.calc_loss_along_seq(test_seq))\n",
    "    res['Model Type'].append(np.repeat(\"Model VI - 32\", max_length-1))\n",
    "    res['Step'].append(np.arange(1, max_length))\n",
    "    \n",
    "    Models = [M1, M12, M2, M3, M41, M42, M43, M44, M51, M52, M53, M54, M61, M62, M63]\n",
    "    ModelNames2 = ['GLM All'] + [f'GLM RO {i}' for i in range(9)] #+[f'GLM KO {i}' for i in range(9)]\n",
    "    \"\"\"\n",
    "    with open(join(loc, file_name), 'rb') as f:\n",
    "        Models, Models2 = pickle.load(f)\n",
    "    \n",
    "    ModelNames = ['Model I - 1', 'Model I - 2', \n",
    "                  'Model II', 'Model III',\n",
    "                  'Model IV - 5', 'Model IV - 10', 'Model IV - 20', 'Model IV - 40',\n",
    "                  'Model V - Reci.', 'Model V - Logis.', 'Model V - Poly2', 'Model V - Poly3',\n",
    "                  'Model VI - 8', 'Model VI - 16', 'Model VI - 32']\n",
    "    \n",
    "    ModelNames2 = ['GLM All'] + [f'GLM RO {i}' for i in range(9)] #+[f'GLM KO {i}' for i in range(9)]\n",
    "    \n",
    "    for i, model in enumerate(Models):\n",
    "        res['Loss'].append(model.calc_loss_along_seq(test_seq))\n",
    "        res['Model Type'].append(np.repeat(ModelNames[i], max_length-1))\n",
    "        res['Step'].append(np.arange(1, max_length))\n",
    "    \"\"\"\n",
    "\n",
    "    X_train, Y_train = np.concatenate([glm_params[i][:-1, :] for i in train_indices], axis=0), np.concatenate([sequences[i][1:] for i in train_indices], axis=0)\n",
    "    nan_sum = np.where(np.isnan(np.sum(X_train, axis=1)) == False)[0]\n",
    "    X_test, Y_test = [glm_params[i] for i in test_indices], [sequences[i] for i in test_indices]   \n",
    "    M2s = []     \n",
    "    for i, _ in enumerate(range(10)):\n",
    "        if i == 0:\n",
    "            model = GenearlizedLinearModel()\n",
    "            model.fit(X_train, Y_train)\n",
    "            res['Loss'].append(model.calc_loss_along_seq(X_test, Y_test))\n",
    "            res['Model Type'].append(np.repeat(ModelNames2[i], max_length-1))\n",
    "            res['Step'].append(np.arange(1, max_length))\n",
    "            M2s.append(model)\n",
    "        elif i >= 1 and i <= 9:\n",
    "            \"\"\"\n",
    "            idx = np.concatenate([np.arange(i-1), np.arange(i, 10)])\n",
    "            model = GenearlizedLinearModel()\n",
    "            model.fit(X_train[:, idx], Y_train)\n",
    "            \n",
    "            res['Loss'].append(model.calc_loss_along_seq([X_test[d][:, idx] for d in range(len(X_test))], Y_test))\n",
    "            res['Model Type'].append(np.repeat(ModelNames2[i], max_length-1))\n",
    "            res['Step'].append(np.arange(1, max_length))\n",
    "            M2s.append(model)\n",
    "        elif i >= 11 and i <= 20:\n",
    "            \"\"\"\n",
    "            model = GenearlizedLinearModel()\n",
    "            model.fit(X_train[:, i-1:i], Y_train)\n",
    "            res['Loss'].append(model.calc_loss_along_seq([X_test[d][:, i-1:i] for d in range(len(X_test))], Y_test))\n",
    "            res['Model Type'].append(np.repeat(ModelNames2[i], max_length-1))\n",
    "            res['Step'].append(np.arange(1, max_length))\n",
    "            M2s.append(model)\n",
    "\n",
    "    if max_length > 10:\n",
    "        sequences, glm_params = tracker.convert_for_glm(field_reg, GLMC, least_length=10, is_seq_format=True, is_gate=is_gate)\n",
    "    else:\n",
    "        sequences, glm_params = tracker.convert_for_glm(field_reg, GLMC, least_length=5, is_seq_format=True, is_gate=is_gate)\n",
    "    \n",
    "    resortidx = np.array([0, 1, 2, 4, 5, 6, 7, 8, 9, 3])\n",
    "    X_train, Y_train = np.concatenate([glm_params[i][:-1, :][:, resortidx] for i in train_indices], axis=0), np.concatenate([sequences[i][1:] for i in train_indices], axis=0)\n",
    "    X_test, Y_test = [glm_params[i][:, resortidx] for i in test_indices], [sequences[i] for i in test_indices] \n",
    "    \n",
    "    nan_sum = np.where(np.isnan(np.sum(X_train, axis=1)) == False)[0]\n",
    "    G2 = GenearlizedLinearModel()\n",
    "    G2.fit(X_train[nan_sum, :], Y_train[nan_sum])\n",
    "\n",
    "    res['Loss'].append(G2.calc_loss_along_seq(X_test, Y_test))\n",
    "    res['Model Type'].append(np.repeat(\"G All + State\", max_length-1))\n",
    "    res['Step'].append(np.arange(1, max_length))\n",
    "    M2s.append(G2)\n",
    "    \n",
    "    predicted_prob = M53.get_predicted_prob(sequences)\n",
    "    X_train = np.vstack([\n",
    "        np.hstack([glm_params[i][:, resortidx][:-1, :], predicted_prob[i][:, np.newaxis]]) for i in train_indices\n",
    "    ])\n",
    "    Y_train = np.concatenate([sequences[i][1:] for i in train_indices])\n",
    "    nan_sum = np.where(np.isnan(np.sum(X_train, axis=1)) == False)[0]\n",
    "    X_test, Y_test = [np.hstack([glm_params[i][:, resortidx], np.append(predicted_prob[i], 0)[:, np.newaxis]]) for i in test_indices], [sequences[i] for i in test_indices] \n",
    "    print(\"G3\")\n",
    "    G3 = GenearlizedLinearModel()\n",
    "    G3.fit(X_train[nan_sum, :], Y_train[nan_sum])\n",
    "    M2s.append(G3)\n",
    "    \n",
    "    res['Loss'].append(G3.calc_loss_along_seq(X_test, Y_test))\n",
    "    res['Model Type'].append(np.repeat(\"G All + Prob\", max_length-1))\n",
    "    res['Step'].append(np.arange(1, max_length))\n",
    "    \n",
    "    with open(join(loc, file_name), 'wb') as f:\n",
    "        pickle.dump([Models, M2s], f)\n",
    "\n",
    "    for k in ['Step', 'Loss', 'Model Type']:\n",
    "        res[k] = np.concatenate(res[k])\n",
    "\n",
    "    return res\n",
    "\n",
    "if os.path.exists(join(figdata, code_id+'.pkl')):\n",
    "    with open(join(figdata, code_id+'.pkl'), 'rb') as handle:\n",
    "        Data = pickle.load(handle)\n",
    "        \n",
    "    for k in Data.keys():\n",
    "        print(k, Data[k].shape)\n",
    "else:\n",
    "    Data = {\n",
    "        'Step': [],\n",
    "        'Paradigm': [],\n",
    "        'MiceID': [],\n",
    "        'Model Type': [],\n",
    "        'Loss': []\n",
    "    }\n",
    "\n",
    "    for i in range(len(f_CellReg_modi)):\n",
    "        if f_CellReg_modi['Type'][i] != 'Real' or f_CellReg_modi['maze_type'][i] == 0:\n",
    "            continue\n",
    "    \n",
    "        print(f_CellReg_modi['Trace File'][i])\n",
    "    \n",
    "        with open(f_CellReg_modi['Trace File'][i], 'rb') as handle:\n",
    "            trace = pickle.load(handle)\n",
    "\n",
    "        if f_CellReg_modi['paradigm'][i] == 'CrossMaze':\n",
    "            mouse = int(f_CellReg_modi['MiceID'][i])\n",
    "            maze_type = int(f_CellReg_modi['maze_type'][i])\n",
    "            paradigm = 'MA' if maze_type == 1 else 'MB'\n",
    "        \n",
    "            glmparams, is_qualified = trace['GLM']\n",
    "            losses = []\n",
    "            for iteration in range(10):\n",
    "                res = fit_models(trace['field_reg'], glmparams, is_qualified, file_name=f\"{mouse}_{paradigm}_iter{iteration}.pkl\")\n",
    "                losses.append(res['Loss'])\n",
    "                \n",
    "            losses = np.vstack(losses)\n",
    "            losses = np.mean(losses, axis=0)\n",
    "        \n",
    "            Data['MiceID'] += [mouse] * len(res['Loss'])\n",
    "            Data['Paradigm'] += [paradigm] * len(res['Loss'])\n",
    "            Data['Model Type'].append(res['Model Type'])\n",
    "            Data['Loss'].append(losses)\n",
    "            Data['Step'].append(res['Step'])\n",
    "            \n",
    "        elif f_CellReg_modi['paradigm'][i] == 'ReverseMaze':\n",
    "            mouse = int(f_CellReg_modi['MiceID'][i])\n",
    "            maze_type = int(f_CellReg_modi['maze_type'][i])\n",
    "            paradigm = 'MAf'\n",
    "        \n",
    "            glmparams, is_qualified = trace['GLM_cis']\n",
    "            losses = []\n",
    "            for iteration in range(10):\n",
    "                res = fit_models(trace['cis']['field_reg'], glmparams, is_qualified, file_name=f\"{mouse}_{paradigm}_iter{iteration}.pkl\")\n",
    "                losses.append(res['Loss'])\n",
    "                \n",
    "            losses = np.vstack(losses)\n",
    "            losses = np.mean(losses, axis=0)\n",
    "        \n",
    "            Data['MiceID'] += [mouse] * len(res['Loss'])\n",
    "            Data['Paradigm'] += [paradigm] * len(res['Loss'])\n",
    "            Data['Model Type'].append(res['Model Type'])\n",
    "            Data['Loss'].append(losses)\n",
    "            Data['Step'].append(res['Step'])\n",
    "            \n",
    "            paradigm = 'MAb'\n",
    "        \n",
    "            glmparams, is_qualified = trace['GLM_trs']\n",
    "            losses = []\n",
    "            for iteration in range(10):\n",
    "                res = fit_models(trace['trs']['field_reg'], glmparams, is_qualified, file_name=f\"{mouse}_{paradigm}_iter{iteration}.pkl\")\n",
    "                losses.append(res['Loss'])\n",
    "                \n",
    "            losses = np.vstack(losses)\n",
    "            losses = np.mean(losses, axis=0)\n",
    "        \n",
    "            Data['MiceID'] += [mouse] * len(res['Loss'])\n",
    "            Data['Paradigm'] += [paradigm] * len(res['Loss'])\n",
    "            Data['Model Type'].append(res['Model Type'])\n",
    "            Data['Loss'].append(losses)\n",
    "            Data['Step'].append(res['Step'])\n",
    "            \n",
    "        elif f_CellReg_modi['paradigm'][i] == 'HairpinMaze':\n",
    "            mouse = int(f_CellReg_modi['MiceID'][i])\n",
    "            maze_type = int(f_CellReg_modi['maze_type'][i])\n",
    "            paradigm = 'HPf'\n",
    "        \n",
    "            glmparams, is_qualified = trace['GLM_cis']\n",
    "            losses = []\n",
    "            for iteration in range(10):\n",
    "                res = fit_models(trace['cis']['field_reg'], glmparams, is_qualified, file_name=f\"{mouse}_{paradigm}_iter{iteration}.pkl\")\n",
    "                losses.append(res['Loss'])\n",
    "                \n",
    "            losses = np.vstack(losses)\n",
    "            losses = np.mean(losses, axis=0)\n",
    "        \n",
    "            Data['MiceID'] += [mouse] * len(res['Loss'])\n",
    "            Data['Paradigm'] += [paradigm] * len(res['Loss'])\n",
    "            Data['Model Type'].append(res['Model Type'])\n",
    "            Data['Loss'].append(losses)\n",
    "            Data['Step'].append(res['Step'])\n",
    "            \n",
    "            paradigm = 'HPb'\n",
    "            \n",
    "            glmparams, is_qualified = trace['GLM_trs']\n",
    "            losses = []\n",
    "            for iteration in range(10):\n",
    "                res = fit_models(trace['trs']['field_reg'], glmparams, is_qualified, file_name=f\"{mouse}_{paradigm}_iter{iteration}.pkl\")\n",
    "                losses.append(res['Loss'])\n",
    "                \n",
    "            losses = np.vstack(losses)\n",
    "            losses = np.mean(losses, axis=0)\n",
    "        \n",
    "            Data['MiceID'] += [mouse] * len(res['Loss'])\n",
    "            Data['Paradigm'] += [paradigm] * len(res['Loss'])\n",
    "            Data['Model Type'].append(res['Model Type'])\n",
    "            Data['Loss'].append(losses)\n",
    "            Data['Step'].append(res['Step'])\n",
    "        print(\"\\n\\n\\n\\n\")\n",
    "        \n",
    "    for k in ['MiceID', 'Paradigm']:\n",
    "        Data[k] = np.array(Data[k])\n",
    "    \n",
    "    for k in ['Model Type', 'Loss', 'Step']:\n",
    "        Data[k] = np.concatenate(Data[k])\n",
    "        \n",
    "    with open(join(figdata, code_id+'.pkl'), 'wb') as handle:\n",
    "        pickle.dump(Data, handle)\n",
    "        \n",
    "    D = pd.DataFrame(Data)\n",
    "    D.to_excel(join(figdata, code_id+'.xlsx'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(join(figdata, code_id+' [without gate].pkl')):\n",
    "    with open(join(figdata, code_id+' [without gate].pkl'), 'rb') as handle:\n",
    "        Data = pickle.load(handle)\n",
    "        \n",
    "    for k in Data.keys():\n",
    "        print(k, Data[k].shape)\n",
    "else:\n",
    "    Data = {\n",
    "        'Step': [],\n",
    "        'Paradigm': [],\n",
    "        'MiceID': [],\n",
    "        'Model Type': [],\n",
    "        'Loss': []\n",
    "    }\n",
    "\n",
    "    for i in range(len(f_CellReg_modi)):\n",
    "        if f_CellReg_modi['Type'][i] != 'Real' or f_CellReg_modi['maze_type'][i] == 0:\n",
    "            continue\n",
    "    \n",
    "        print(f_CellReg_modi['Trace File'][i])\n",
    "    \n",
    "        with open(f_CellReg_modi['Trace File'][i], 'rb') as handle:\n",
    "            trace = pickle.load(handle)\n",
    "\n",
    "        if f_CellReg_modi['paradigm'][i] == 'CrossMaze':\n",
    "            mouse = int(f_CellReg_modi['MiceID'][i])\n",
    "            maze_type = int(f_CellReg_modi['maze_type'][i])\n",
    "            paradigm = 'MA' if maze_type == 1 else 'MB'\n",
    "        \n",
    "            glmparams, is_qualified = trace['GLM']\n",
    "            losses = []\n",
    "            for iteration in range(10):\n",
    "                res = fit_models(trace['field_reg'], glmparams, is_qualified, file_name=f\"[wg] {mouse}_{paradigm}_iter{iteration}.pkl\", is_gate=False)\n",
    "                losses.append(res['Loss'])\n",
    "                \n",
    "            losses = np.vstack(losses)\n",
    "            losses = np.mean(losses, axis=0)\n",
    "        \n",
    "            Data['MiceID'] += [mouse] * len(res['Loss'])\n",
    "            Data['Paradigm'] += [paradigm] * len(res['Loss'])\n",
    "            Data['Model Type'].append(res['Model Type'])\n",
    "            Data['Loss'].append(losses)\n",
    "            Data['Step'].append(res['Step'])\n",
    "            \n",
    "        elif f_CellReg_modi['paradigm'][i] == 'ReverseMaze':\n",
    "            mouse = int(f_CellReg_modi['MiceID'][i])\n",
    "            maze_type = int(f_CellReg_modi['maze_type'][i])\n",
    "            paradigm = 'MAf'\n",
    "        \n",
    "            glmparams, is_qualified = trace['GLM_cis']\n",
    "            losses = []\n",
    "            for iteration in range(10):\n",
    "                res = fit_models(trace['cis']['field_reg'], glmparams, is_qualified, file_name=f\"[wg] {mouse}_{paradigm}_iter{iteration}.pkl\", is_gate=False)\n",
    "                losses.append(res['Loss'])\n",
    "                \n",
    "            losses = np.vstack(losses)\n",
    "            losses = np.mean(losses, axis=0)\n",
    "        \n",
    "            Data['MiceID'] += [mouse] * len(res['Loss'])\n",
    "            Data['Paradigm'] += [paradigm] * len(res['Loss'])\n",
    "            Data['Model Type'].append(res['Model Type'])\n",
    "            Data['Loss'].append(losses)\n",
    "            Data['Step'].append(res['Step'])\n",
    "            \n",
    "            paradigm = 'MAb'\n",
    "        \n",
    "            glmparams, is_qualified = trace['GLM_trs']\n",
    "            losses = []\n",
    "            for iteration in range(10):\n",
    "                res = fit_models(trace['trs']['field_reg'], glmparams, is_qualified, file_name=f\"[wg] {mouse}_{paradigm}_iter{iteration}.pkl\", is_gate=False)\n",
    "                losses.append(res['Loss'])\n",
    "                \n",
    "            losses = np.vstack(losses)\n",
    "            losses = np.mean(losses, axis=0)\n",
    "        \n",
    "            Data['MiceID'] += [mouse] * len(res['Loss'])\n",
    "            Data['Paradigm'] += [paradigm] * len(res['Loss'])\n",
    "            Data['Model Type'].append(res['Model Type'])\n",
    "            Data['Loss'].append(losses)\n",
    "            Data['Step'].append(res['Step'])\n",
    "            \n",
    "        elif f_CellReg_modi['paradigm'][i] == 'HairpinMaze':\n",
    "            mouse = int(f_CellReg_modi['MiceID'][i])\n",
    "            maze_type = int(f_CellReg_modi['maze_type'][i])\n",
    "            paradigm = 'HPf'\n",
    "        \n",
    "            glmparams, is_qualified = trace['GLM_cis']\n",
    "            losses = []\n",
    "            for iteration in range(10):\n",
    "                res = fit_models(trace['cis']['field_reg'], glmparams, is_qualified, file_name=f\"[wg] {mouse}_{paradigm}_iter{iteration}.pkl\", is_gate=False)\n",
    "                losses.append(res['Loss'])\n",
    "                \n",
    "            losses = np.vstack(losses)\n",
    "            losses = np.mean(losses, axis=0)\n",
    "        \n",
    "            Data['MiceID'] += [mouse] * len(res['Loss'])\n",
    "            Data['Paradigm'] += [paradigm] * len(res['Loss'])\n",
    "            Data['Model Type'].append(res['Model Type'])\n",
    "            Data['Loss'].append(losses)\n",
    "            Data['Step'].append(res['Step'])\n",
    "            \n",
    "            paradigm = 'HPb'\n",
    "            \n",
    "            glmparams, is_qualified = trace['GLM_trs']\n",
    "            losses = []\n",
    "            for iteration in range(10):\n",
    "                res = fit_models(trace['trs']['field_reg'], glmparams, is_qualified, file_name=f\"[wg] {mouse}_{paradigm}_iter{iteration}.pkl\", is_gate=False)\n",
    "                losses.append(res['Loss'])\n",
    "                \n",
    "            losses = np.vstack(losses)\n",
    "            losses = np.mean(losses, axis=0)\n",
    "        \n",
    "            Data['MiceID'] += [mouse] * len(res['Step'])\n",
    "            Data['Paradigm'] += [paradigm] * len(res['Step'])\n",
    "            Data['Model Type'].append(res['Model Type'])\n",
    "            Data['Loss'].append(losses)\n",
    "            Data['Step'].append(res['Step'])\n",
    "        print(\"\\n\\n\\n\\n\")\n",
    "        \n",
    "    for k in ['MiceID', 'Paradigm']:\n",
    "        Data[k] = np.array(Data[k])\n",
    "    \n",
    "    for k in ['Model Type', 'Loss', 'Step']:\n",
    "        Data[k] = np.concatenate(Data[k])\n",
    "        \n",
    "    with open(join(figdata, code_id+' [without gate].pkl'), 'wb') as handle:\n",
    "        pickle.dump(Data, handle)\n",
    "        \n",
    "    D = pd.DataFrame(Data)\n",
    "    D.to_excel(join(figdata, code_id+' [without gate].xlsx'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelNames = ['Model I - 2', \n",
    "                  'Model II', #'Model III',\n",
    "                  'Model IV - 5', 'Model IV - 10', 'Model IV - 20', 'Model IV - 40',\n",
    "                  'Model V - reci', 'Model V - Logis.', 'Model V - Poly2', 'Model V - Poly3',\n",
    "                  'Model VI - 8', 'Model VI - 16', 'Model VI - 32']\n",
    "    \n",
    "ModelNames2 = ['Model I - 1', 'GLM All'] + ['G All + State', 'G All + Prob'] + [f'GLM RO {i}' for i in range(9)]\n",
    "\n",
    "# Statistical test\n",
    "stat_names = ModelNames + ModelNames2\n",
    "for i in [6, 12, 18]:\n",
    "    mat = np.zeros((len(stat_names), len(stat_names)))\n",
    "    SubData = SubDict(Data, Data.keys(), np.where(Data['Step'] == i)[0])\n",
    "    for j in range(len(stat_names)-1):\n",
    "        for k in range(j+1, len(stat_names)):\n",
    "            mat[j, k] = ttest_rel(SubData['Loss'][SubData['Model Type'] == stat_names[j]], SubData['Loss'][SubData['Model Type'] == stat_names[k]])[1]\n",
    "            mat[k, j] = mat[j, k]\n",
    "    \n",
    "    D = pd.DataFrame(mat, index=stat_names, columns=stat_names)\n",
    "    D.to_excel(join(figdata, code_id+f'_loss_stat_step{i}.xlsx'), index=False)\n",
    "\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    ax = Clear_Axes(plt.axes())\n",
    "    ax.imshow(mat, vmin=0, vmax=4, aspect='equal')\n",
    "    plt.show()\n",
    "idx = np.where(np.isin(Data['Model Type'], ModelNames+ModelNames2))[0]\n",
    "Data = SubDict(Data, Data.keys(), idx)\n",
    "\n",
    "idx = np.where(Data['Step'] == 6)[0]\n",
    "SubData = SubDict(Data, Data.keys(), idx)\n",
    "a = np.mean(SubData['Loss'][SubData['Model Type'] == 'Model I - 1'])\n",
    "b = np.mean(SubData['Loss'][SubData['Model Type'] == 'Model I - 2'])\n",
    "print(np.where(SubData['Model Type'] == 'Model I - 1')[0].shape[0])\n",
    "fig = plt.figure(figsize=(10, 2))\n",
    "ax = Clear_Axes(plt.axes(), close_spines=['top', 'right'], ifxticks=True, ifyticks=True)\n",
    "ax.axhline(a, 0, 30, color='k', ls='--', linewidth=0.5)\n",
    "ax.axhline(b, 0, 30, color='k', ls='--', linewidth=0.5)\n",
    "sns.boxplot(\n",
    "    x='Model Type',\n",
    "    y='Loss',\n",
    "    hue='Model Type',\n",
    "    data=SubData,\n",
    "    order=ModelNames + ModelNames2,\n",
    "    hue_order=ModelNames + ModelNames2,\n",
    "    palette=ModelPalette,\n",
    "    linecolor='black',\n",
    "    linewidth=0.5,\n",
    "    gap=0.3,\n",
    "    flierprops={'markersize': 1},\n",
    ")\n",
    "ax.set_ylim(0.3, 0.8)\n",
    "ax.set_yticks(np.linspace(0.3, 0.8, 11))\n",
    "plt.savefig(join(loc, \"step 7.png\"), dpi=600)\n",
    "plt.savefig(join(loc, \"step 7.svg\"), dpi=600)\n",
    "plt.show()\n",
    "\n",
    "idx = np.where(Data['Step'] == 12)[0]\n",
    "SubData = SubDict(Data, Data.keys(), idx)\n",
    "a = np.mean(SubData['Loss'][SubData['Model Type'] == 'Model I - 1'])\n",
    "b = np.mean(SubData['Loss'][SubData['Model Type'] == 'Model I - 2'])\n",
    "print(np.where(SubData['Model Type'] == 'Model I - 1')[0].shape[0])\n",
    "fig = plt.figure(figsize=(10, 2))\n",
    "ax = Clear_Axes(plt.axes(), close_spines=['top', 'right'], ifxticks=True, ifyticks=True)\n",
    "ax.axhline(a, 0, 30, color='k', ls='--', linewidth=0.5)\n",
    "ax.axhline(b, 0, 30, color='k', ls='--', linewidth=0.5)\n",
    "sns.boxplot(\n",
    "    x='Model Type',\n",
    "    y='Loss',\n",
    "    hue='Model Type',\n",
    "    data=SubData,\n",
    "    palette=ModelPalette,\n",
    "    order=ModelNames + ModelNames2,\n",
    "    hue_order=ModelNames + ModelNames2,\n",
    "    linecolor='black',\n",
    "    linewidth=0.5,\n",
    "    gap=0.3,\n",
    "    flierprops={'markersize': 1},\n",
    ")\n",
    "ax.set_ylim(0.3, 0.8)\n",
    "ax.set_yticks(np.linspace(0.3, 0.8, 11))\n",
    "plt.savefig(join(loc, \"step 13.png\"), dpi=600)\n",
    "plt.savefig(join(loc, \"step 13.svg\"), dpi=600)\n",
    "plt.show()\n",
    "\n",
    "idx = np.where(Data['Step'] == 18)[0]\n",
    "SubData = SubDict(Data, Data.keys(), idx)\n",
    "a = np.mean(SubData['Loss'][SubData['Model Type'] == 'Model I - 1'])\n",
    "b = np.mean(SubData['Loss'][SubData['Model Type'] == 'Model I - 2'])\n",
    "print(np.where(SubData['Model Type'] == 'Model I - 1')[0].shape[0])\n",
    "fig = plt.figure(figsize=(10, 2))\n",
    "ax = Clear_Axes(plt.axes(), close_spines=['top', 'right'], ifxticks=True, ifyticks=True)\n",
    "ax.axhline(a, 0, 30, color='k', ls='--', linewidth=0.5)\n",
    "ax.axhline(b, 0, 30, color='k', ls='--', linewidth=0.5)\n",
    "sns.boxplot(\n",
    "    x='Model Type',\n",
    "    y='Loss',\n",
    "    hue='Model Type',\n",
    "    data=SubData,\n",
    "    palette=ModelPalette,\n",
    "    order=ModelNames + ModelNames2,\n",
    "    hue_order=ModelNames + ModelNames2,\n",
    "    linecolor='black',\n",
    "    linewidth=0.5,\n",
    "    gap=0.3,\n",
    "    flierprops={'markersize': 1},\n",
    ")\n",
    "ax.set_ylim(0.3, 0.7)\n",
    "ax.set_yticks(np.linspace(0.3, 0.7, 9))\n",
    "plt.savefig(join(loc, \"step 21.png\"), dpi=600)\n",
    "plt.savefig(join(loc, \"step 21.svg\"), dpi=600)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mylib.statistic_test import *\n",
    "\n",
    "code_id = '0346 - GLM for all sessions'\n",
    "loc = os.path.join(figpath, code_id)\n",
    "mkdir(loc)\n",
    "\n",
    "from mylib.model.glms import GLM as GenearlizedLinearModel\n",
    "from mylib.model import EqualRateDriftModel, TwoProbDriftModel\n",
    "from mylib.model import TwoProbabilityIndependentModel\n",
    "from mylib.model import JointProbabilityModel\n",
    "from mylib.model import HMM\n",
    "from mylib.model import ContinuousHiddenStateModel\n",
    "from mylib.model import ProbabilityRNN, IntegrativeRNN\n",
    "\n",
    "from mylib.field.tracker_v2 import Tracker2d\n",
    "\n",
    "if exists(join(figdata, code_id+' [coefficients].pkl')):\n",
    "    with open(join(figdata, code_id+' [coefficients].pkl'), 'rb') as f:\n",
    "        Coef = pickle.load(f)\n",
    "else:\n",
    "    Coef = {\n",
    "        \"MiceID\": [],\n",
    "        \"Paradigm\": [],\n",
    "        \"Coefficients\": [],\n",
    "        \"Coefficient Name\": []\n",
    "    }\n",
    "    \n",
    "    for i in range(len(f_CellReg_modi)):\n",
    "        if f_CellReg_modi['Type'][i] != 'Real' or f_CellReg_modi['maze_type'][i] == 0:\n",
    "            continue\n",
    "    \n",
    "        print(f_CellReg_modi['Trace File'][i])\n",
    "    \n",
    "        with open(f_CellReg_modi['Trace File'][i], 'rb') as handle:\n",
    "            trace = pickle.load(handle)\n",
    "\n",
    "        param_names = ['Constant'] + [f\"{i}\" for i in range(9)]\n",
    "        if f_CellReg_modi['paradigm'][i] == 'CrossMaze':\n",
    "            mouse = int(f_CellReg_modi['MiceID'][i])\n",
    "            paradigm = 'MA' if f_CellReg_modi['maze_type'][i] == 1 else 'MB'\n",
    "            \n",
    "            ef = []\n",
    "            for iteration in range(10):\n",
    "                with open(join(loc, f\"{mouse}_{paradigm}_iter{iteration}.pkl\"), 'rb') as f:\n",
    "                    models, models_glm = pickle.load(f)\n",
    "                    \n",
    "                params = models_glm[0].results.params\n",
    "                ef.append(params)\n",
    "            \n",
    "            ef = np.vstack(ef)\n",
    "            Coef['MiceID'].append(np.repeat(mouse, len(params)))\n",
    "            Coef['Paradigm'].append(np.repeat(paradigm, len(params)))\n",
    "            Coef['Coefficients'].append(np.mean(ef, axis=0))\n",
    "            Coef['Coefficient Name'].append(np.arange(10))\n",
    "        else:\n",
    "            for dirs in ['cis', 'trs']:\n",
    "                if f_CellReg_modi['paradigm'][i] == 'ReverseMaze':\n",
    "                    paradigm = 'MAf' if dirs == 'cis' else 'MAb'\n",
    "                else:\n",
    "                    paradigm = 'HPf' if dirs == 'cis' else 'HPb'\n",
    "                    \n",
    "                mouse = int(f_CellReg_modi['MiceID'][i])\n",
    "                \n",
    "                ef = []\n",
    "                for iteration in range(10):\n",
    "                    with open(join(loc, f\"{mouse}_{paradigm}_iter{iteration}.pkl\"), 'rb') as f:\n",
    "                        models, models_glm = pickle.load(f)\n",
    "                    params = models_glm[0].results.params\n",
    "                    ef.append(params)\n",
    "                \n",
    "                ef = np.vstack(ef)\n",
    "                Coef['MiceID'].append(np.repeat(mouse, len(params)))\n",
    "                Coef['Paradigm'].append(np.repeat(paradigm, len(params)))\n",
    "                Coef['Coefficients'].append(np.mean(ef, axis=0))\n",
    "                Coef['Coefficient Name'].append(np.arange(10))\n",
    "        \n",
    "    for k in Coef.keys():\n",
    "        Coef[k] = np.concatenate(Coef[k])\n",
    "    \n",
    "    with open(join(figdata, code_id+' [coefficients].pkl'), 'wb') as f:\n",
    "        pickle.dump(Coef, f)\n",
    "        \n",
    "    D = pd.DataFrame(Coef)\n",
    "    D.to_excel(join(figdata, code_id+' [coefficients].xlsx'), index=False)\n",
    "    \n",
    "fig = plt.figure(figsize=(6, 2))\n",
    "ax = Clear_Axes(plt.axes(), close_spines=['top', 'right'], ifxticks=True, ifyticks=True)\n",
    "\n",
    "sns.boxplot(\n",
    "    x = 'Coefficient Name',\n",
    "    y = 'Coefficients',\n",
    "    hue = 'Coefficient Name',\n",
    "    palette=['#6ED3CF']+sns.color_palette(\"rainbow\", 9),\n",
    "    data=Coef,\n",
    "    linewidth=0.5,\n",
    "    linecolor='black',\n",
    "    gap=0.3,\n",
    "    flierprops={'markersize': 1, 'color':'black'},\n",
    "    ax=ax\n",
    ")\n",
    "ax.axhline(0, color='k', ls='--', linewidth=0.5)\n",
    "ax.set_ylim(-1.5, 1.5)\n",
    "ax.set_yticks(np.linspace(-1.5, 1.5, 7))\n",
    "plt.savefig(join(loc, \"coefficients.png\"), dpi=600)\n",
    "plt.savefig(join(loc, \"coefficients.svg\"), dpi=600)\n",
    "plt.show()\n",
    "\n",
    "for k in np.unique(Coef['Coefficient Name']):\n",
    "    idx = np.where(Coef['Coefficient Name'] == k)[0]\n",
    "    print(f\"Coef {k}, {len(idx)}: {ttest_1samp(Coef['Coefficients'][idx], 0)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maze",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
