{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda\\envs\\maze\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        E:\\Data\\FinalResults\\0346 - GLM for all sessions is already existed!\n",
      "Using device: cuda\n",
      "Using device: cuda\n",
      "Using device: cuda\n",
      "E:\\Data\\Hairpin_maze\\10209\\footprint\\Cell_reg\\trace_mdays_conc.pkl\n",
      "Orignial shape: (7, 5114), qualified shape: 2660\n",
      "Simple Drift Model:\n",
      "  Loss: [0.69152222 0.69271517 0.70166227 0.707627   0.71273125 0.71573362]\n",
      "  Parameters: (0.5287481015404643,).\n",
      "\n",
      "Two Probability Drift Model:\n",
      "  Loss: [0.70329872 0.64965921 0.60605816 0.54941147 0.51147465 0.53477727]\n",
      "  Parameters: (0.6042154566744731, 0.22215709261430247).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 768/768 [00:00<00:00, 249610.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retention + Recovery Model:\n",
      "  Loss: [0.69211047 0.63386045 0.57822857 0.52346375 0.4807547  0.54131898]\n",
      "  Retention Parameters: [2.22335803 3.89288971]\n",
      "  Recovery Parameters: [0.69751982 1.38478845].\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "e:\\Anaconda\\envs\\maze\\lib\\site-packages\\mylib\\field\\tracker_v2.py:324: RuntimeWarning: invalid value encountered in divide\n",
      "  probs = probs[1:, :, 1]/np.sum(probs[1:, :, :], axis=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint Probability Model:\n",
      "  Loss: [0.69441278 0.63551942 0.56235685 0.54345293 0.5064775  0.61567684]\n",
      "  Parameters: [-0.23045001  1.42185712  1.16240109  1.56895198].\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 84.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Markov Model with 5 hidden states:\n",
      "  Loss: [0.69529684 0.65285124 0.56333843 0.54143421 0.49139649 0.57439509]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 85.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Markov Model with 10 hidden states:\n",
      "  Loss: [0.69839503 0.65752764 0.56371647 0.53776853 0.49054622 0.58120553]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 86.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Markov Model with 20 hidden states:\n",
      "  Loss: [0.69897407 0.65896954 0.56408125 0.53716333 0.49068246 0.58263342]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 56.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Markov Model with 40 hidden states:\n",
      "  Loss: [0.69929144 0.66005158 0.56438176 0.53717643 0.49103996 0.58351477]\n",
      "\n",
      "Continuous Hidden State Model with reci:\n",
      "  Loss: [0.69157343 0.6401577  0.5710398  0.53024032 0.48309735 0.54499902]\n",
      "\n",
      "Continuous Hidden State Model with logistic:\n",
      "  Loss: [0.69157343 0.63775477 0.5708499  0.5261523  0.48126692 0.54407659]\n",
      "\n",
      "Continuous Hidden State Model with poly2:\n",
      "  Loss: [0.69157343 0.64200095 0.57397394 0.52195231 0.48091883 0.54413259]\n",
      "\n",
      "Continuous Hidden State Model with poly3:\n",
      "  Loss: [0.69157343 0.66567792 0.58246813 0.54101076 0.47929856 0.58473438]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 477/1000 [00:10<00:10, 48.33it/s]"
     ]
    }
   ],
   "source": [
    "from mylib.statistic_test import *\n",
    "\n",
    "code_id = '0346 - GLM for all sessions'\n",
    "loc = os.path.join(figpath, code_id)\n",
    "mkdir(loc)\n",
    "\n",
    "from mylib.model.glms import GLM as GenearlizedLinearModel\n",
    "from mylib.model import EqualRateDriftModel, TwoProbDriftModel\n",
    "from mylib.model import TwoProbabilityIndependentModel\n",
    "from mylib.model import JointProbabilityModel\n",
    "from mylib.model import HMM\n",
    "from mylib.model import ContinuousHiddenStateModel\n",
    "from mylib.model import ProbabilityRNN, IntegrativeRNN\n",
    "\n",
    "from mylib.field.tracker_v2 import Tracker2d\n",
    "\n",
    "def fit_models(field_reg, GLM: np.ndarray, qualified_idx: np.ndarray, file_name: str):\n",
    "    Models = {}\n",
    "\n",
    "    res = {\n",
    "        \"Step\": [],\n",
    "        \"Loss\": [],\n",
    "        \"Model Type\": []\n",
    "    }\n",
    "    \n",
    "    # Standardization\n",
    "    for j in range(GLM.shape[2]):\n",
    "        mean, std = np.nanmean(GLM[:, :, j]), np.nanstd(GLM[:, :, j])\n",
    "        GLM[:, :, j] = (GLM[:, :, j] - mean) / std\n",
    "    \n",
    "    GLM = GLM[:, :, [0, 1, 2, 4, 5, 6, 7, 8, 9, 10]]\n",
    "    print(f\"Orignial shape: {field_reg.shape}, qualified shape: {qualified_idx.shape[0]}\")\n",
    "    #field_reg = field_reg[:, qualified_idx]\n",
    "    tracker = Tracker2d(field_reg=field_reg)\n",
    "    sequences = tracker.convert_to_sequence()\n",
    "    lengths = np.array([len(seq) for seq in sequences])\n",
    "    \n",
    "    max_length = np.max(lengths)\n",
    "    if max_length > 10:\n",
    "        sequences, glm_params = tracker.convert_for_glm(field_reg, GLM, least_length=10, is_seq_format=True)\n",
    "    else:\n",
    "        sequences, glm_params = tracker.convert_for_glm(field_reg, GLM, least_length=5, is_seq_format=True)\n",
    "    \n",
    "    train_size = int(len(sequences) * 0.8)\n",
    "    train_indices = np.random.choice(len(sequences), train_size, replace=False)\n",
    "    test_indices = np.setdiff1d(np.arange(len(sequences)), train_indices)\n",
    "    res['train_indices'] = train_indices\n",
    "    res['train_size'] = 0.8\n",
    "    res['sequences'] = sequences\n",
    "    \n",
    "    train_seq = [sequences[i] for i in train_indices]\n",
    "    test_seq = [sequences[i] for i in test_indices]\n",
    "    M1 = EqualRateDriftModel()\n",
    "    M1.fit(train_seq)\n",
    "    res['Loss'].append(M1.calc_loss_along_seq(test_seq))\n",
    "    res['Model Type'].append(np.repeat(\"Model I - 1\", max_length-1))\n",
    "    res['Step'].append(np.arange(1, max_length))\n",
    "    res['Step'].append(np.arange(1, max_length))\n",
    "    \n",
    "    M12 = TwoProbDriftModel()\n",
    "    M12.fit(train_seq)\n",
    "    res['Loss'].append(M12.calc_loss_along_seq(test_seq))\n",
    "    res['Model Type'].append(np.repeat(\"Model I - 2\", max_length-1))\n",
    "    res['Step'].append(np.arange(1, max_length))\n",
    "\n",
    "    M2 = TwoProbabilityIndependentModel()\n",
    "    M2.fit(train_seq)\n",
    "    res['Loss'].append(M2.calc_loss_along_seq(test_seq))\n",
    "    res['Model Type'].append(np.repeat(\"Model II\", max_length-1))\n",
    "    res['Step'].append(np.arange(1, max_length))\n",
    "\n",
    "    M3 = JointProbabilityModel()\n",
    "    M3.fit(train_seq)\n",
    "    res['Loss'].append(M3.calc_loss_along_seq(test_seq))\n",
    "    res['Model Type'].append(np.repeat(\"Model III\", max_length-1))\n",
    "    res['Step'].append(np.arange(1, max_length))\n",
    "\n",
    "    M41 = HMM.process_fit(N=5, sequences=train_seq, n_iterations=100)\n",
    "    res['Loss'].append(M41.calc_loss_along_seq(test_seq))\n",
    "    res['Model Type'].append(np.repeat(\"Model IV - 5\", max_length-1))\n",
    "    res['Step'].append(np.arange(1, max_length))\n",
    "    \n",
    "    M42 = HMM.process_fit(N=10, sequences=train_seq, n_iterations=100)\n",
    "    res['Loss'].append(M42.calc_loss_along_seq(test_seq))\n",
    "    res['Model Type'].append(np.repeat(\"Model IV - 10\", max_length-1))\n",
    "    res['Step'].append(np.arange(1, max_length))\n",
    "\n",
    "    M43 = HMM.process_fit(N=20, sequences=train_seq, n_iterations=100)\n",
    "    res['Loss'].append(M43.calc_loss_along_seq(test_seq))\n",
    "    res['Model Type'].append(np.repeat(\"Model IV - 20\", max_length-1))\n",
    "    res['Step'].append(np.arange(1, max_length))\n",
    "\n",
    "    M44 = HMM.process_fit(N=40, sequences=train_seq, n_iterations=100)\n",
    "    res['Loss'].append(M44.calc_loss_along_seq(test_seq))\n",
    "    res['Model Type'].append(np.repeat(\"Model IV - 40\", max_length-1))\n",
    "    res['Step'].append(np.arange(1, max_length))\n",
    "\n",
    "    M51 = ContinuousHiddenStateModel('reci')\n",
    "    M51.fit(train_seq)\n",
    "    res['Loss'].append(M51.calc_loss_along_seq(test_seq))\n",
    "    res['Model Type'].append(np.repeat(\"Model V - reci\", max_length-1))\n",
    "    res['Step'].append(np.arange(1, max_length))\n",
    "\n",
    "    M52 = ContinuousHiddenStateModel('logistic')\n",
    "    M52.fit(train_seq)\n",
    "    res['Loss'].append(M52.calc_loss_along_seq(test_seq))\n",
    "    res['Model Type'].append(np.repeat(\"Model V - logistic\", max_length-1))\n",
    "    res['Step'].append(np.arange(1, max_length))\n",
    "\n",
    "    M53 = ContinuousHiddenStateModel('poly2')\n",
    "    M53.fit(train_seq)\n",
    "    res['Loss'].append(M53.calc_loss_along_seq(test_seq))\n",
    "    res['Model Type'].append(np.repeat(\"Model V - poly2\", max_length-1))\n",
    "    res['Step'].append(np.arange(1, max_length))\n",
    "    \n",
    "    M54 = ContinuousHiddenStateModel('poly3')\n",
    "    M54.fit(train_seq)\n",
    "    res['Loss'].append(M54.calc_loss_along_seq(test_seq))\n",
    "    res['Model Type'].append(np.repeat(\"Model V - poly3\", max_length-1))\n",
    "    res['Step'].append(np.arange(1, max_length))\n",
    "\n",
    "    M61 = ProbabilityRNN.process_fit(\n",
    "        sequences,\n",
    "        train_index=train_indices,\n",
    "        hidden_size=8,\n",
    "        lr=0.001,\n",
    "        epochs=1000, \n",
    "        batch_size=2048\n",
    "    )\n",
    "    res['Loss'].append(M61.calc_loss_along_seq(test_seq))\n",
    "    res['Model Type'].append(np.repeat(\"Model VI - 8\", max_length-1)) \n",
    "    res['Step'].append(np.arange(1, max_length))\n",
    "\n",
    "    M62 = ProbabilityRNN.process_fit(\n",
    "        sequences,\n",
    "        train_index=train_indices,\n",
    "        hidden_size=16,\n",
    "        lr=0.001,\n",
    "        epochs=1000, \n",
    "        batch_size=2048\n",
    "    )\n",
    "    res['Loss'].append(M62.calc_loss_along_seq(test_seq))\n",
    "    res['Model Type'].append(np.repeat(\"Model VI - 16\", max_length-1)) \n",
    "    res['Step'].append(np.arange(1, max_length))\n",
    "\n",
    "    M63 = ProbabilityRNN.process_fit(\n",
    "        sequences,\n",
    "        train_index=train_indices,\n",
    "        hidden_size=32,\n",
    "        lr=0.001,\n",
    "        epochs=1000, \n",
    "        batch_size=2048\n",
    "    )\n",
    "    res['Loss'].append(M63.calc_loss_along_seq(test_seq))\n",
    "    res['Model Type'].append(np.repeat(\"Model VI - 32\", max_length-1))\n",
    "    res['Step'].append(np.arange(1, max_length))\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    # Process NAN values\n",
    "    for i in range(len(sequences)):\n",
    "        nanidx = np.where(np.isnan(glm_params[i][:, :6]))[0]\n",
    "        if len(nanidx) > 0:\n",
    "            glm_params[i][nanidx] = 0\n",
    "        \n",
    "        # First Lap Appear\n",
    "        nanidx = np.where(np.isnan(glm_params[i][:, 6]))[0]\n",
    "        # Get session id\n",
    "        if len(nanidx) > 0:\n",
    "            session_id = glm_params[i][nanidx, 1].astype(int)-1\n",
    "            glm_params[i][nanidx, 6] = np.nanmax(GLM[session_id, :, 6], axis=1)+1\n",
    "        \n",
    "        # BTSP-like signature\n",
    "        nanidx = np.where(np.isnan(glm_params[i][:, [7,8]]))[0]\n",
    "        if len(nanidx) > 0:   \n",
    "            glm_params[i][nanidx, :][:, [7,8]] = 1\n",
    "        \n",
    "        # Fluctuation\n",
    "        nanidx = np.where(np.isnan(glm_params[i][:, 9]))[0]\n",
    "        if len(nanidx) > 0:    \n",
    "            session_id = glm_params[i][nanidx, 1].astype(int)-1\n",
    "            glm_params[i][nanidx, 9] = np.nanmean(GLM[session_id, :, 9], axis=1)\n",
    "    \"\"\"\n",
    "    X_train, Y_train = np.concatenate([glm_params[i][:-1, :] for i in train_indices], axis=0), np.concatenate([sequences[i][1:] for i in train_indices], axis=0)\n",
    "    nan_sum = np.where(np.isnan(np.sum(X_train, axis=1)) == False)[0]\n",
    "    X_test, Y_test = [glm_params[i] for i in test_indices], [sequences[i] for i in test_indices]\n",
    "    G1 = GenearlizedLinearModel()\n",
    "    G1.fit(X_train[nan_sum, :], Y_train[nan_sum])\n",
    "    res['Loss'].append(G1.calc_loss_along_seq(X_test, Y_test))\n",
    "    res['Model Type'].append(np.repeat(\"GLM All\", max_length-1))\n",
    "    res['Step'].append(np.arange(1, max_length))\n",
    "    \n",
    "    # Knockout one models\n",
    "    KO = []\n",
    "    for i in range(10):\n",
    "        print(f\"Knock out element {i}\")\n",
    "        GKO = GenearlizedLinearModel()\n",
    "        idx = np.concatenate([np.arange(i), np.arange(i+1, 10)])\n",
    "        GKO.fit(X_train[:, idx][nan_sum, :], Y_train[nan_sum])\n",
    "        res['Loss'].append(GKO.calc_loss_along_seq([X_test[d][:, idx] for d in range(len(X_test))], Y_test))\n",
    "        res['Model Type'].append(np.repeat(f\"GLM KO {i}\", max_length-1))\n",
    "        KO.append(GKO)\n",
    "        res['Step'].append(np.arange(1, max_length))\n",
    "        \n",
    "    # Only One\n",
    "    RO = []\n",
    "    for i in range(10):\n",
    "        print(f\"Only element {i}\")\n",
    "        GRO = GenearlizedLinearModel()\n",
    "        GRO.fit(X_train[:, i:i+1][nan_sum, :], Y_train[nan_sum])\n",
    "        res['Loss'].append(GRO.calc_loss_along_seq([X_test[d][:, i:i+1] for d in range(len(X_test))], Y_test))\n",
    "        res['Model Type'].append(np.repeat(f\"GLM RO {i}\", max_length-1))\n",
    "        RO.append(GRO)\n",
    "        res['Step'].append(np.arange(1, max_length))\n",
    "\n",
    "    \"\"\"\n",
    "    integrative_seq = [\n",
    "        np.hstack([sequences[i][:, np.newaxis], glm_params[i]]) for i in range(len(sequences))\n",
    "    ]\n",
    "    M71 = IntegrativeRNN.process_fit(\n",
    "        sequences=integrative_seq,\n",
    "        train_index=train_indices,\n",
    "        hidden_size=8,\n",
    "        lr=0.001,\n",
    "        epochs=1000, \n",
    "        batch_size=32\n",
    "    )\n",
    "    res['Loss'].append(M71.calc_loss_along_seq(test_seq))\n",
    "    res['Model Type'].append(np.repeat(\"Model VII - 8\", max_length-1))\n",
    "    res['Step'].append(np.arange(1, max_length))\n",
    "    \n",
    "    M72 = IntegrativeRNN.process_fit(\n",
    "        sequences=integrative_seq,\n",
    "        train_index=train_indices,\n",
    "        hidden_size=16,\n",
    "        lr=0.001,\n",
    "        epochs=1000, \n",
    "        batch_size=32\n",
    "    )\n",
    "    res['Loss'].append(M72.calc_loss_along_seq(test_seq))\n",
    "    res['Model Type'].append(np.repeat(\"Model VII - 16\", max_length-1))\n",
    "    res['Step'].append(np.arange(1, max_length))\n",
    "    \n",
    "    M73 = IntegrativeRNN.process_fit(\n",
    "        sequences=integrative_seq,\n",
    "        train_index=train_indices,\n",
    "        hidden_size=32,\n",
    "        lr=0.001,\n",
    "        epochs=1000, \n",
    "        batch_size=32\n",
    "    )\n",
    "    res['Loss'].append(M73.calc_loss_along_seq(test_seq))\n",
    "    res['Model Type'].append(np.repeat(\"Model Venus - 32\", max_length-1))\n",
    "    res['Step'].append(np.arange(1, max_length))\n",
    "    \"\"\"\n",
    "    Models = [M1, M12, M2, M3, M41, M42, M43, M44, M51, M52, M53, M54, M61, M62, M63]\n",
    "    Models2 = [G1] + KO + RO\n",
    "    \n",
    "    with open(join(loc, file_name), 'wb') as f:\n",
    "        pickle.dump([Models, Models2], f)\n",
    "\n",
    "    for k in ['Step', 'Loss', 'Model Type']:\n",
    "        res[k] = np.concatenate(res[k])\n",
    "\n",
    "    return res\n",
    "\n",
    "if os.path.exists(join(figdata, code_id+'.pkl')):\n",
    "    with open(join(figdata, code_id+'.pkl'), 'rb') as handle:\n",
    "        Data = pickle.load(handle)\n",
    "else:\n",
    "    Data = {\n",
    "        'Step': [],\n",
    "        'Paradigm': [],\n",
    "        'MiceID': [],\n",
    "        'Model Type': [],\n",
    "        'Loss': []\n",
    "    }\n",
    "\n",
    "    for i in range(26, len(f_CellReg_modi)):\n",
    "        if f_CellReg_modi['Type'][i] != 'Real' or f_CellReg_modi['maze_type'][i] == 0:\n",
    "            continue\n",
    "    \n",
    "        print(f_CellReg_modi['Trace File'][i])\n",
    "    \n",
    "        with open(f_CellReg_modi['Trace File'][i], 'rb') as handle:\n",
    "            trace = pickle.load(handle)\n",
    "\n",
    "        if f_CellReg_modi['paradigm'][i] == 'CrossMaze':\n",
    "            mouse = int(f_CellReg_modi['MiceID'][i])\n",
    "            maze_type = int(f_CellReg_modi['maze_type'][i])\n",
    "            paradigm = 'MA' if maze_type == 1 else 'MB'\n",
    "        \n",
    "            glmparams, is_qualified = trace['GLM']\n",
    "            losses = []\n",
    "            for iteration in range(10):\n",
    "                res = fit_models(trace['field_reg'], glmparams, is_qualified, file_name=f\"{mouse}_{paradigm}_iter{iteration}.pkl\")\n",
    "                losses.append(res['Loss'])\n",
    "                \n",
    "            losses = np.vstack(losses)\n",
    "            losses = np.mean(losses, axis=0)\n",
    "        \n",
    "            Data['MiceID'] += [mouse] * len(res['Loss'])\n",
    "            Data['Paradigm'] += [paradigm] * len(res['Loss'])\n",
    "            Data['Model Type'].append(res['Model Type'])\n",
    "            Data['Loss'].append(losses)\n",
    "            Data['Step'].append(res['Step'])\n",
    "            \n",
    "        elif f_CellReg_modi['paradigm'][i] == 'ReverseMaze':\n",
    "            mouse = int(f_CellReg_modi['MiceID'][i])\n",
    "            maze_type = int(f_CellReg_modi['maze_type'][i])\n",
    "            paradigm = 'MAf'\n",
    "        \n",
    "            glmparams, is_qualified = trace['GLM_cis']\n",
    "            losses = []\n",
    "            for iteration in range(10):\n",
    "                res = fit_models(trace['cis']['field_reg'], glmparams, is_qualified, file_name=f\"{mouse}_{paradigm}_iter{iteration}.pkl\")\n",
    "                losses.append(res['Loss'])\n",
    "                \n",
    "            losses = np.vstack(losses)\n",
    "            losses = np.mean(losses, axis=0)\n",
    "        \n",
    "            Data['MiceID'] += [mouse] * len(res['Loss'])\n",
    "            Data['Paradigm'] += [paradigm] * len(res['Loss'])\n",
    "            Data['Model Type'].append(res['Model Type'])\n",
    "            Data['Loss'].append(losses)\n",
    "            Data['Step'].append(res['Step'])\n",
    "            \n",
    "            paradigm = 'MAb'\n",
    "        \n",
    "            glmparams, is_qualified = trace['GLM_trs']\n",
    "            losses = []\n",
    "            for iteration in range(10):\n",
    "                res = fit_models(trace['trs']['field_reg'], glmparams, is_qualified, file_name=f\"{mouse}_{paradigm}_iter{iteration}.pkl\")\n",
    "                losses.append(res['Loss'])\n",
    "                \n",
    "            losses = np.vstack(losses)\n",
    "            losses = np.mean(losses, axis=0)\n",
    "        \n",
    "            Data['MiceID'] += [mouse] * len(res['Loss'])\n",
    "            Data['Paradigm'] += [paradigm] * len(res['Loss'])\n",
    "            Data['Model Type'].append(res['Model Type'])\n",
    "            Data['Loss'].append(losses)\n",
    "            Data['Step'].append(res['Step'])\n",
    "            \n",
    "        elif f_CellReg_modi['paradigm'][i] == 'HairpinMaze':\n",
    "            mouse = int(f_CellReg_modi['MiceID'][i])\n",
    "            maze_type = int(f_CellReg_modi['maze_type'][i])\n",
    "            paradigm = 'HPf'\n",
    "        \n",
    "            glmparams, is_qualified = trace['GLM_cis']\n",
    "            losses = []\n",
    "            for iteration in range(10):\n",
    "                res = fit_models(trace['cis']['field_reg'], glmparams, is_qualified, file_name=f\"{mouse}_{paradigm}_iter{iteration}.pkl\")\n",
    "                losses.append(res['Loss'])\n",
    "                \n",
    "            losses = np.vstack(losses)\n",
    "            losses = np.mean(losses, axis=0)\n",
    "        \n",
    "            Data['MiceID'] += [mouse] * len(res['Loss'])\n",
    "            Data['Paradigm'] += [paradigm] * len(res['Loss'])\n",
    "            Data['Model Type'].append(res['Model Type'])\n",
    "            Data['Loss'].append(losses)\n",
    "            Data['Step'].append(res['Step'])\n",
    "            \n",
    "            paradigm = 'HPb'\n",
    "            \n",
    "            glmparams, is_qualified = trace['GLM_trs']\n",
    "            losses = []\n",
    "            for iteration in range(10):\n",
    "                res = fit_models(trace['trs']['field_reg'], glmparams, is_qualified, file_name=f\"{mouse}_{paradigm}_iter{iteration}.pkl\")\n",
    "                losses.append(res['Loss'])\n",
    "                \n",
    "            losses = np.vstack(losses)\n",
    "            losses = np.mean(losses, axis=0)\n",
    "        \n",
    "            Data['MiceID'] += [mouse] * len(res['Loss'])\n",
    "            Data['Paradigm'] += [paradigm] * len(res['Loss'])\n",
    "            Data['Model Type'].append(res['Model Type'])\n",
    "            Data['Loss'].append(losses)\n",
    "            Data['Step'].append(res['Step'])\n",
    "        print(\"\\n\\n\\n\\n\")\n",
    "        \n",
    "    for k in ['MiceID', 'Paradigm']:\n",
    "        Data[k] = np.array(Data[k])\n",
    "    \n",
    "    for k in ['Model Type', 'Loss', 'Step']:\n",
    "        Data[k] = np.concatenate(Data[k])\n",
    "        \n",
    "    with open(join(figdata, code_id+'.pkl'), 'wb') as handle:\n",
    "        pickle.dump(Data, handle)\n",
    "        \n",
    "    D = pd.DataFrame(Data)\n",
    "    D.to_excel(join(figdata, code_id+'.xlsx'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maze",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
